# ğŸ“˜ Pro RAG Checkpoint & Essentials Guide

This document covers all essential information for developers and users of the **Pro RAG Chatbot**. It details the setup, configuration, features, and technical architecture of the project.

---

## ğŸ› ï¸ Installation & Setup

### 1. Prerequisites
- **Python 3.10+**: Required for modern type hinting and libraries.
- **Git**: For version control.
- **Ollama**: (Optional) For running local models. Download from [ollama.com](https://ollama.com).

### 2. Quick Start
These commands will get you running in minutes:

```bash
# Clone the repository
git clone https://github.com/ShibilAhamed701212/RAGLLM.git
cd RAGLLM

# Create a virtual environment (recommended)
python -m venv venv
# Windows:
.\venv\Scripts\activate
# Mac/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 3. Dependencies
The project relies on these key libraries:
- **Streamlit**: The web interface framework.
- **LangChain**: Core logic for RAG (Retrieval-Augmented Generation).
- **Ollama**: Local LLM integration.
- **OpenAI**: Cloud LLM integration.
- **FAISS**: High-performance vector database for document search.
- **fpdf2**: PDF generation for chat exports.
- **FastEmbed**: Lightweight embedding generation (CPU-optimized).

---

## âš™ï¸ Configuration (.env)

You can customize the application behavior using environment variables. Create a `.env` file in the root directory:

```env
# â”€â”€ Core Settings â”€â”€
# "ollama" (default) or "openai"
LLM_PROVIDER=ollama
LLM_MODEL=llama3.2:3b

# â”€â”€ Cloud API Keys â”€â”€
# Required if LLM_PROVIDER is "openai" (or entered via UI sidebar)
OPENAI_API_KEY=sk-proj-...

# â”€â”€ RAG Parameters â”€â”€
# Number of document chunks to retrieve per query
TOP_K=5
# Creativity: 0.0 (precise) to 1.0 (creative)
DEFAULT_TEMPERATURE=0.3
# Chunk size for splitting documents (tokens)
CHUNK_SIZE=500
CHUNK_OVERLAP=50
```

---

## ğŸš€ Key Features

### 1. Hybrid Intelligence (Local + Cloud)
- **Local (Ollama)**: Use models like Llama 3, Mistral, Gemma for privacy and offline use.
- **Cloud (OpenAI)**: Use GPT-4o, GPT-4 Turbo for maximum reasoning power. Enter your API key directly in the sidebar or `.env`.

### 2. Document Processing
- **Upload**: Supports PDF, TXT, MD.
- **Web Ingest**: Paste any URL to ingest its content.
- **Vector Search**: Uses FAISS for semantic similarity search.

### 3. Advanced UI
- **3D Immersive Design**: Glassmorphism, animated backgrounds, and neon accents.
- **Dark Mode**: High-contrast, easy-on-the-eyes theme.
- **Responsive**: Sidebar overflow protection and mobile-friendly layout.

### 4. Export Capabilities
- **PDF Export**: Download your full conversation as a beautifully formatted PDF.
- **Markdown Export**: Download raw text for notes or documentation.

---

## ğŸ“‚ Project Structure

```
RAGLLM/
â”œâ”€â”€ app.py              # Main Streamlit application entry point
â”œâ”€â”€ cli.py              # Terminal-based chat interface
â”œâ”€â”€ requirements.txt    # Python package dependencies
â”œâ”€â”€ .env                # Configuration file (gitignored)
â”œâ”€â”€ .gitignore          # Git exclusion rules
â”œâ”€â”€ src/                # Core logic implementation
â”‚   â”œâ”€â”€ config.py       # Configuration loading & constants
â”‚   â”œâ”€â”€ utils.py        # LLM, Embedding, & FAISS helpers (API logic here)
â”‚   â”œâ”€â”€ ingestion.py    # Document processing & chunking logic
â”‚   â””â”€â”€ core.py         # RAG pipeline & prompt engineering
â”œâ”€â”€ data/               # Directory for uploaded user files
â””â”€â”€ vector_index/       # Local FAISS index storage
```

---

## ğŸ›¡ï¸ Git Best Practices

- **Ignore Private Data**: The `.gitignore` file is configured to exclude:
    - `.env` (API keys)
    - `data/` (Uploaded documents)
    - `vector_index/` (Generated embeddings)
    - `.chat_sessions.json` (Your private chat history)
    - `venv/` (Python environment)

This ensures you can safely push code updates without leaking sensitive information.

---

## ğŸ¤ Contributing

1.  **Fork the repo**.
2.  **Create a branch**: `git checkout -b feature/new-cool-thing`.
3.  **Make changes**: Edit `app.py` for UI or `src/` for logic.
4.  **Test**: Run `streamlit run app.py` and verify functionality.
5.  **Push**: `git push origin feature/new-cool-thing`.
6.  **Open a Pull Request**.

---

*Generated by Pro RAG Assistant.*
